package com.retail.dolphinpos.data.workers

import android.content.Context
import android.util.Log
import androidx.hilt.work.HiltWorker
import androidx.work.CoroutineWorker
import androidx.work.WorkerParameters
import androidx.work.workDataOf
import com.retail.dolphinpos.data.dao.BatchDao
import com.retail.dolphinpos.data.entities.user.BatchSyncStatus
import com.retail.dolphinpos.data.service.ApiService
import com.retail.dolphinpos.domain.model.auth.cash_denomination.BatchCloseRequest
import com.retail.dolphinpos.domain.model.auth.cash_denomination.BatchOpenRequest
import dagger.assisted.Assisted
import dagger.assisted.AssistedInject
import retrofit2.HttpException

/**
 * Unified WorkManager worker that syncs batch operations (START and CLOSE) to the backend.
 * 
 * CRITICAL OPERATIONS:
 * 1. Batch START Sync:
 *    - Queries batches with syncStatus = START_PENDING (regardless of lifecycle status)
 *    - Calls batch start API
 *    - On success: Updates syncStatus = START_SYNCED (batch IDs are always generated by POS)
 *    - Special case: If batch is already CLOSED, also updates to CLOSE_PENDING for close sync
 *    - On failure: Updates syncStatus = FAILED, retries with WorkManager backoff
 * 
 * 2. Batch CLOSE Sync:
 *    - Queries batches with syncStatus = CLOSE_PENDING (must be CLOSED and START_SYNCED)
 *    - Calls batch close API
 *    - On success: Updates syncStatus = CLOSE_SYNCED
 *    - On failure: Updates syncStatus = FAILED, retries with WorkManager backoff
 * 
 * SYNC FLOW EXAMPLES:
 * 
 * Example 1: Batch starts offline, stays open
 * - Start: lifecycleStatus=OPEN, syncStatus=START_PENDING
 * - Sync: START syncs → syncStatus=START_SYNCED
 * - Close later: lifecycleStatus=CLOSED, syncStatus=CLOSE_PENDING
 * - Sync: CLOSE syncs → syncStatus=CLOSE_SYNCED
 * 
 * Example 2: Batch starts offline, closes offline before any sync
 * - Start: lifecycleStatus=OPEN, syncStatus=START_PENDING
 * - Close: lifecycleStatus=CLOSED, syncStatus=START_PENDING (unchanged - START must sync first)
 * - Sync: START syncs → syncStatus=START_SYNCED, then auto-updates to CLOSE_PENDING
 * - Sync: CLOSE syncs → syncStatus=CLOSE_SYNCED
 * 
 * IMPORTANT: 
 * - Batch START must be synced before orders can be synced
 * - Batch CLOSE can happen offline and is synced later
 * - Batch START must exist on server before CLOSE can be synced
 * - APIs are idempotent, so safe to retry
 */
@HiltWorker
class BatchSyncWorker @AssistedInject constructor(
    @Assisted context: Context,
    @Assisted params: WorkerParameters,
    private val batchDao: BatchDao,
    private val apiService: ApiService
) : CoroutineWorker(context, params) {
    
    companion object {
        const val TAG = "BatchSyncWorker"
    }
    
    override suspend fun doWork(): Result {
        return try {
            Log.d(TAG, "Starting batch sync worker")
            
            var hasWork = false
            var hasErrors = false
            
            // Step 1: Sync batch START operations
            val startSyncResult = syncBatchStarts()
            hasWork = hasWork || startSyncResult.hasWork
            hasErrors = hasErrors || startSyncResult.hasErrors
            
            // Step 2: Sync batch CLOSE operations
            val closeSyncResult = syncBatchCloses()
            hasWork = hasWork || closeSyncResult.hasWork
            hasErrors = hasErrors || closeSyncResult.hasErrors
            
            if (!hasWork) {
                Log.d(TAG, "No batches need syncing")
                return Result.success()
            }
            
            if (hasErrors) {
                // Some operations failed, retry with backoff
                Log.w(TAG, "Some batch sync operations failed, will retry")
                return Result.retry()
            }
            
            Log.d(TAG, "Batch sync completed successfully")
            Result.success()
            
        } catch (e: Exception) {
            Log.e(TAG, "Error in batch sync worker: ${e.message}", e)
            Result.retry()
        }
    }
    
    /**
     * Syncs batch START operations for batches with START_PENDING status.
     * 
     * IMPORTANT: Backend only allows ONE active batch per register at a time.
     * Strategy:
     * 1. Prioritize syncing the currently OPEN batch (most recent)
     * 2. For CLOSED batches, only sync if there's no newer OPEN batch
     * 3. Handle "Batch already active" errors gracefully (mark as synced if batch exists on server)
     */
    private suspend fun syncBatchStarts(): SyncResult {
        val pendingBatches = batchDao.getBatchesNeedingStartSync()
        
        if (pendingBatches.isEmpty()) {
            return SyncResult(hasWork = false, hasErrors = false)
        }
        
        Log.d(TAG, "Found ${pendingBatches.size} batches needing START sync")
        
        // Separate OPEN and CLOSED batches
        val openBatches = pendingBatches.filter { 
            it.lifecycleStatus == com.retail.dolphinpos.data.entities.user.BatchLifecycleStatus.OPEN 
        }
        val closedBatches = pendingBatches.filter { 
            it.lifecycleStatus == com.retail.dolphinpos.data.entities.user.BatchLifecycleStatus.CLOSED 
        }
        
        // Strategy: Sync OPEN batch first (there should only be one)
        // Then, only sync CLOSED batches if there's no OPEN batch blocking them
        val batchesToSync = if (openBatches.isNotEmpty()) {
            // If there's an OPEN batch, only sync that one (most recent)
            // Don't sync closed batches because the backend won't accept them
            // (there's already an active batch - the OPEN one we're syncing)
            listOf(openBatches.first()) // Take the first (should be only one)
        } else {
            // No OPEN batch, sync closed batches (oldest first to maintain order)
            closedBatches.sortedBy { it.openedAt }
        }
        
        if (batchesToSync.isEmpty()) {
            Log.d(TAG, "No batches to sync after filtering")
            return SyncResult(hasWork = false, hasErrors = false)
        }
        
        Log.d(TAG, "Syncing ${batchesToSync.size} batch(es) for START (${openBatches.size} OPEN, ${closedBatches.size} CLOSED)")
        
        var successCount = 0
        var failureCount = 0
        var conflictSkippedCount = 0
        
        for (batch in batchesToSync) {
            try {
                // Validate required fields first
                val storeId = batch.storeId
                if (storeId == null) {
                    Log.e(TAG, "Batch ${batch.batchId} missing storeId")
                    batchDao.updateBatchSyncStatus(batch.batchId, BatchSyncStatus.FAILED)
                    failureCount++
                    continue
                }
                
                val userId = batch.userId
                if (userId == null) {
                    Log.e(TAG, "Batch ${batch.batchId} missing userId")
                    batchDao.updateBatchSyncStatus(batch.batchId, BatchSyncStatus.FAILED)
                    failureCount++
                    continue
                }
                
                val locationId = batch.locationId
                if (locationId == null) {
                    Log.e(TAG, "Batch ${batch.batchId} missing locationId")
                    batchDao.updateBatchSyncStatus(batch.batchId, BatchSyncStatus.FAILED)
                    failureCount++
                    continue
                }
                
                // Prepare batch open request
                val batchOpenRequest = BatchOpenRequest(
                    batchNo = batch.batchNo,
                    storeId = storeId,
                    userId = userId,
                    locationId = locationId,
                    storeRegisterId = batch.registerId,
                    startingCashAmount = batch.startingCashAmount
                )
                
                // Call backend API
                Log.d(TAG, "Syncing batch start for ${batch.batchId} (${batch.lifecycleStatus}) to backend...")
                val response = apiService.batchOpen(batchOpenRequest)
                
                // Mark batch start as synced
                batchDao.markBatchStartAsSynced(batch.batchId)
                
                // If batch is already closed, update it to CLOSE_PENDING for close sync
                if (batch.lifecycleStatus == com.retail.dolphinpos.data.entities.user.BatchLifecycleStatus.CLOSED) {
                    batchDao.markClosedBatchAsClosePendingAfterStartSync(batch.batchId)
                    Log.d(TAG, "Batch ${batch.batchId} was already closed, updated to CLOSE_PENDING for close sync")
                }
                
                Log.d(TAG, "Batch ${batch.batchId} start synced successfully")
                successCount++
                
            } catch (e: HttpException) {
                when (e.code()) {
                    422 -> {
                        // 422 Unprocessable Entity - often means "Batch already active"
                        val errorBody = try {
                            e.response()?.errorBody()?.string()
                        } catch (ex: Exception) {
                            null
                        }
                        Log.w(TAG, "HTTP 422 for batch ${batch.batchId}: $errorBody")
                        
                        // Check if error is "Batch already active" - this means there's already an active batch on server
                        // This happens when multiple batches try to sync or when backend state differs from local
                        if (errorBody?.contains("Batch already active", ignoreCase = true) == true) {
                            // If this is the OPEN batch, we can't sync it because another batch is active
                            // This is a conflict - we'll leave it as START_PENDING to retry later
                            // (The backend's active batch might get closed, allowing this one to sync)
                            Log.w(TAG, "Batch ${batch.batchId} cannot sync: backend has active batch for this register. Will retry later.")
                            // Don't mark as synced or failed - leave as START_PENDING for retry
                            // This allows the sync to retry when the backend's active batch is closed
                            conflictSkippedCount++
                        } else {
                            // Other validation errors (e.g., invalid starting cash amount)
                            Log.e(TAG, "Validation error for batch ${batch.batchId}: $errorBody")
                            batchDao.updateBatchSyncStatus(batch.batchId, BatchSyncStatus.FAILED)
                            failureCount++
                        }
                    }
                    else -> {
                        Log.e(TAG, "HTTP error syncing batch start for ${batch.batchId}: ${e.code()} ${e.message()}", e)
                        batchDao.updateBatchSyncStatus(batch.batchId, BatchSyncStatus.FAILED)
                        failureCount++
                    }
                }
            } catch (e: Exception) {
                Log.e(TAG, "Error syncing batch start for ${batch.batchId}: ${e.message}", e)
                batchDao.updateBatchSyncStatus(batch.batchId, BatchSyncStatus.FAILED)
                failureCount++
            }
        }
        
        // For any batches we skipped upfront (CLOSED batches when there's an OPEN batch)
        val upfrontSkipped = if (openBatches.isNotEmpty() && closedBatches.isNotEmpty()) {
            closedBatches.size
        } else {
            0
        }
        
        if (upfrontSkipped > 0) {
            Log.d(TAG, "Skipped $upfrontSkipped CLOSED batches upfront because OPEN batch exists (will sync after OPEN batch is synced and closed)")
        }
        
        val totalSkipped = upfrontSkipped + conflictSkippedCount
        if (totalSkipped > 0) {
            Log.d(TAG, "Batch START sync skipped $totalSkipped batches (${upfrontSkipped} upfront, $conflictSkippedCount due to conflicts)")
        }
        
        Log.d(TAG, "Batch START sync complete: $successCount succeeded, $failureCount failed, $totalSkipped skipped")
        
        // Only retry if we have failures (not if we only have skips)
        return SyncResult(hasWork = true, hasErrors = failureCount > 0)
    }
    
    /**
     * Syncs batch CLOSE operations for batches with CLOSE_PENDING status.
     */
    private suspend fun syncBatchCloses(): SyncResult {
        val pendingBatches = batchDao.getBatchesNeedingCloseSync()
        
        if (pendingBatches.isEmpty()) {
            return SyncResult(hasWork = false, hasErrors = false)
        }
        
        Log.d(TAG, "Found ${pendingBatches.size} batches needing CLOSE sync")
        
        var successCount = 0
        var failureCount = 0
        
        for (batch in pendingBatches) {
            try {
                // Validate required fields first
                val userId = batch.userId
                if (userId == null) {
                    Log.e(TAG, "Batch ${batch.batchId} missing userId")
                    batchDao.updateBatchSyncStatus(batch.batchId, BatchSyncStatus.FAILED)
                    failureCount++
                    continue
                }
                
                val closingCashAmount = batch.closingCashAmount
                if (closingCashAmount == null) {
                    Log.e(TAG, "Batch ${batch.batchId} missing closingCashAmount")
                    batchDao.updateBatchSyncStatus(batch.batchId, BatchSyncStatus.FAILED)
                    failureCount++
                    continue
                }
                
                val locationId = batch.locationId
                if (locationId == null) {
                    Log.e(TAG, "Batch ${batch.batchId} missing locationId")
                    batchDao.updateBatchSyncStatus(batch.batchId, BatchSyncStatus.FAILED)
                    failureCount++
                    continue
                }
                
                val storeId = batch.storeId
                if (storeId == null) {
                    Log.e(TAG, "Batch ${batch.batchId} missing storeId")
                    batchDao.updateBatchSyncStatus(batch.batchId, BatchSyncStatus.FAILED)
                    failureCount++
                    continue
                }
                
                // Batch IDs are always generated by POS, so we use batchNo to identify the batch on server
                val batchCloseRequest = BatchCloseRequest(
                    cashierId = userId,
                    closedBy = userId, // Using userId as closedBy
                    closingCashAmount = closingCashAmount,
                    locationId = locationId,
                    orders = emptyList(), // Orders are synced separately
                    paxBatchNo = "", // TODO: Add PAX batch number if available
                    storeId = storeId
                )
                
                // Call backend API using batchNo to identify the batch
                Log.d(TAG, "Syncing batch close for ${batch.batchId} (batchNo: ${batch.batchNo}) to backend...")
                val response = apiService.batchClose(batch.batchNo, batchCloseRequest)
                
                // Mark batch close as synced
                batchDao.markBatchCloseAsSynced(batch.batchId)
                
                Log.d(TAG, "Batch ${batch.batchId} close synced successfully. Server message: ${response.message}")
                successCount++
                
            } catch (e: HttpException) {
                Log.e(TAG, "HTTP error syncing batch close for ${batch.batchId}: ${e.code()} ${e.message()}", e)
                batchDao.updateBatchSyncStatus(batch.batchId, BatchSyncStatus.FAILED)
                failureCount++
            } catch (e: Exception) {
                Log.e(TAG, "Error syncing batch close for ${batch.batchId}: ${e.message}", e)
                batchDao.updateBatchSyncStatus(batch.batchId, BatchSyncStatus.FAILED)
                failureCount++
            }
        }
        
        Log.d(TAG, "Batch CLOSE sync complete: $successCount succeeded, $failureCount failed")
        return SyncResult(hasWork = true, hasErrors = failureCount > 0)
    }
    
    /**
     * Result of sync operation indicating if work was done and if there were errors.
     */
    private data class SyncResult(
        val hasWork: Boolean,
        val hasErrors: Boolean
    )
}

